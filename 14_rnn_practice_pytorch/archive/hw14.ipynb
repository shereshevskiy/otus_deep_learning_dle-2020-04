{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Домашнее задание\n",
    "# <center>Создаем Википедию\n",
    "1. Используя подход аналогичный torchvision, сделать свой класс датасета.   \n",
    "Необязательное д/з:   \n",
    "1. Поэкспериментировать с разными архитектурами рекурренток: тип ячеек, слои, нормализация, методы оптимизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiText2Dataset:\n",
    "    \n",
    "    def __init__(self, batch_size=128, eval_batch_size=128, sequence_length=30, tokenize_func=list):\n",
    "        self.tokenize_func = tokenize_func\n",
    "        self.batch_size = batch_size\n",
    "        self.eval_batch_size = eval_batch_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.symbol2idx = None\n",
    "        self.idx2symbol = None\n",
    "        self.TEXT = None\n",
    "        self.train_txt, self.val_txt, self.test_txt = None, None, None\n",
    "        self.make_TextLoader_cls()\n",
    "    \n",
    "    def get_train_val_test_txts(self):\n",
    "        self.TEXT = torchtext.data.Field(tokenize=get_tokenizer(self.tokenize_func),\n",
    "                                    init_token='<sos>',\n",
    "                                    eos_token='<eos>',\n",
    "                                    lower=False)\n",
    "        self.train_txt, self.val_txt, self.test_txt = torchtext.datasets.WikiText2.splits(self.TEXT)\n",
    "        self.TEXT.build_vocab(self.train_txt)\n",
    "        self.symbol2idx = self.TEXT.vocab.stoi\n",
    "        self.idx2symbol = self.TEXT.vocab.itos\n",
    "        return self.train_txt, self.val_txt, self.test_txt\n",
    "    \n",
    "\n",
    "    def _batchify(self, data_txt, batch_size):\n",
    "        data = self.TEXT.numericalize([data_txt.examples[0].text])\n",
    "        # Divide the dataset into bsz parts.\n",
    "        nbatch = data.size(0) // batch_size\n",
    "        # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "        data = data.narrow(0, 0, nbatch * batch_size)\n",
    "        # Evenly divide the data across the bsz batches.\n",
    "        data = data.view(batch_size, -1).t().contiguous()\n",
    "        \n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # data = data.to(device)\n",
    "        return data\n",
    "    \n",
    "    def get_train_loader(self):\n",
    "        if self.train_txt is None:\n",
    "            self.get_train_val_test_txts()\n",
    "        train_data = self._batchify(self.train_txt, self.batch_size)\n",
    "        train_loader = self.TextLoader(train_data, self.sequence_length)\n",
    "        return train_loader\n",
    "\n",
    "    def get_val_loader(self):\n",
    "        if self.val_txt is None:\n",
    "            self.get_train_val_test_txts()\n",
    "        val_data = self._batchify(self.val_txt, self.eval_batch_size)\n",
    "        val_loader = self.TextLoader(val_data, self.sequence_length)\n",
    "        return val_loader\n",
    "    \n",
    "    def get_test_loader(self):\n",
    "        if self.test_txt is None:\n",
    "            self.get_train_val_test_txts()\n",
    "        test_data = self._batchify(self.test_txt, self.eval_batch_size)\n",
    "        test_loader = self.TextLoader(test_data, self.sequence_length)\n",
    "        return test_loader\n",
    "    \n",
    "    def make_TextLoader_cls(self):\n",
    "        class TextLoader:\n",
    "            def __init__(self, batch_data, sequence_length=30):\n",
    "                self.batch_data = batch_data\n",
    "                self.sequence_length = sequence_length\n",
    "\n",
    "            def _get_batch(self, i):\n",
    "                seq_len = min(self.sequence_length, len(self.batch_data) - 1 - i)\n",
    "                data = self.batch_data[i:i+seq_len]\n",
    "                target = self.batch_data[i+1:i+1+seq_len].view(-1)\n",
    "                return data, target\n",
    "\n",
    "            def __iter__(self):\n",
    "                for i in range(0, self.batch_data.size(0) - 1, self.sequence_length):\n",
    "                    data, targets = self._get_batch(i)\n",
    "                    yield data, targets\n",
    "\n",
    "            def __len__(self):\n",
    "                return self.batch_data.size(0)\n",
    "        self.TextLoader = TextLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## тестируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = WikiText2Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_loader = dataset.get_train_loader()\n",
    "val_loader = dataset.get_val_loader()\n",
    "test_loader = dataset.get_test_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 4,  5,  6,  ..., 17,  4,  7],\n",
       "         [ 3, 11,  4,  ..., 11,  6, 23],\n",
       "         [ 4, 23, 18,  ..., 10,  9,  5],\n",
       "         ...,\n",
       "         [41,  4,  4,  ...,  5,  4,  6],\n",
       "         [ 4, 64,  7,  ...,  4, 15, 13],\n",
       "         [35, 10, 20,  ..., 31, 10,  5]]),\n",
       " tensor([ 3, 11,  4,  ..., 46, 19,  4]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_loader)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 128])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_loader)[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3840])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_loader)[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 4,  5, 52,  ..., 15, 14,  7],\n",
       "         [ 3,  4,  4,  ...,  9,  4, 11],\n",
       "         [ 4, 12, 24,  ...,  8, 19,  4],\n",
       "         ...,\n",
       "         [ 4,  6,  8,  ..., 13,  4, 70],\n",
       "         [47, 11, 20,  ...,  8, 27, 16],\n",
       "         [ 9, 16, 15,  ...,  4,  4,  5]]),\n",
       " tensor([ 3,  4,  4,  ..., 29,  3, 15]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(val_loader)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 4,  6, 14,  ..., 15, 12, 29],\n",
       "         [ 3,  6, 10,  ..., 15,  4, 16],\n",
       "         [ 4, 11, 19,  ...,  7, 16,  8],\n",
       "         ...,\n",
       "         [ 5, 10, 10,  ...,  4, 11,  6],\n",
       "         [11,  8,  9,  ..., 27,  5, 23],\n",
       "         [ 6,  4,  8,  ...,  4,  4, 15]]),\n",
       " tensor([ 3,  6, 10,  ...,  3, 37,  5]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test_loader)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
