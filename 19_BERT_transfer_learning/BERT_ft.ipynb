{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jNKaJz5j_ylj"
   },
   "source": [
    "## BERT fine tunning\n",
    "*Based on [BERT Fine-Tuning Sentence Classification notebook on Colab](https://colab.research.google.com/drive/1ywsvwO6thOVOrfagjjfuxEf6xVRxbUNO#scrollTo=6J-FYdx6nFE_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2M9rmOzwnwzf"
   },
   "source": [
    "We will use BERT implementation from `pytorch-transformers` library, which contains almost all recent architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "id": "0NmMdkZO8R6q",
    "outputId": "d70d236d-9855-4615-a91e-d221aab07e7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
      "\u001b[K     |████████████████████████████████| 184kB 2.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2019.12.20)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.18.5)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.14.20)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.41.1)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 8.7MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 15.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.5.1+cu101)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.23.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.20 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.17.20)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (0.16.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->pytorch-transformers) (0.16.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.20->boto3->pytorch-transformers) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.20->boto3->pytorch-transformers) (0.15.2)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=3cef633b1c8fbed533f43c1a9c97755c956d3b16a345d62d87262ca6159aec2f\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sentencepiece, sacremoses, pytorch-transformers\n",
      "Successfully installed pytorch-transformers-1.2.0 sacremoses-0.0.43 sentencepiece-0.1.91\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "id": "Ok002ceNB8E7",
    "outputId": "d7bd0934-5e18-4f4d-8663-8d13e692622e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_transformers import BertTokenizer, BertConfig\n",
    "from pytorch_transformers import AdamW, BertForSequenceClassification\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5gP8XxgBnwzp"
   },
   "source": [
    "Если у вас есть GPU, будем использовать ее для обучения. Тем не менее, этот ноутбук можно выполнить и с помощью только CPU. Правда, это будет значительно дольше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "id": "oYsV4H8fCpZ-",
    "outputId": "55ae8050-4a40-4b7a-9e98-4c500ce49588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Tesla P100-PCIE-16GB GPUs\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if device == torch.device('cpu'):\n",
    "    print('Using cpu')\n",
    "else:\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    print('Using {} GPUs'.format(torch.cuda.get_device_name(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "guw6ZNtaswKc"
   },
   "source": [
    "## Загрузка данных\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7L8ygZnYnwzv"
   },
   "source": [
    "Мы выбрали не очень известный, необычный датасет с разметкой сентимента русскоязычных твитов (подробнее про него в [статье](http://www.swsys.ru/index.php?page=article&id=3962&lang=)). В корпусе, который мы использовали 114,911 положительных и 111,923 отрицательных записей. Загрузить его можно [тут](https://study.mokoron.com/).\n",
    "\n",
    "Но и wget сойдет, сайт без аутентификации и потому скать просто."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "colab_type": "code",
    "id": "Mgz4IORDo05G",
    "outputId": "e872a142-a623-4bf6-f1b5-7e062f2bb48d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-15 10:26:03--  https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv?dl=0\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.82.1, 2620:100:6032:1::a27d:5201\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.82.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/fnpq3z4bcnoktiv/positive.csv [following]\n",
      "--2020-07-15 10:26:03--  https://www.dropbox.com/s/raw/fnpq3z4bcnoktiv/positive.csv\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc1050ef87a445a8574fcc7de9a0.dl.dropboxusercontent.com/cd/0/inline/A7mU6RHhbQ_--fCuUIwZSqeOKNUCMk1rvwqCshaZwEfMb_6dGsq-CkTjb5sOxL5Ii1yInCj1VEarikgaC6vntTxtKNroN2fSvPNxpHtogFnL_g/file# [following]\n",
      "--2020-07-15 10:26:03--  https://uc1050ef87a445a8574fcc7de9a0.dl.dropboxusercontent.com/cd/0/inline/A7mU6RHhbQ_--fCuUIwZSqeOKNUCMk1rvwqCshaZwEfMb_6dGsq-CkTjb5sOxL5Ii1yInCj1VEarikgaC6vntTxtKNroN2fSvPNxpHtogFnL_g/file\n",
      "Resolving uc1050ef87a445a8574fcc7de9a0.dl.dropboxusercontent.com (uc1050ef87a445a8574fcc7de9a0.dl.dropboxusercontent.com)... 162.125.82.15, 2620:100:6032:15::a27d:520f\n",
      "Connecting to uc1050ef87a445a8574fcc7de9a0.dl.dropboxusercontent.com (uc1050ef87a445a8574fcc7de9a0.dl.dropboxusercontent.com)|162.125.82.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 26233379 (25M) [text/plain]\n",
      "Saving to: ‘positive.csv?dl=0’\n",
      "\n",
      "positive.csv?dl=0   100%[===================>]  25.02M  14.4MB/s    in 1.7s    \n",
      "\n",
      "2020-07-15 10:26:06 (14.4 MB/s) - ‘positive.csv?dl=0’ saved [26233379/26233379]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "colab_type": "code",
    "id": "zRpFxexjo5Ks",
    "outputId": "b3d21e29-1b4b-4dce-8110-102580985e59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-15 10:26:08--  https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv?dl=0\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.82.1, 2620:100:6032:1::a27d:5201\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.82.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/r6u59ljhhjdg6j0/negative.csv [following]\n",
      "--2020-07-15 10:26:09--  https://www.dropbox.com/s/raw/r6u59ljhhjdg6j0/negative.csv\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc36031389b61b3493f3f9bc803d.dl.dropboxusercontent.com/cd/0/inline/A7lJpPqc811NfH-q40zkD1CQ9uk6fKWLqesO-UHyd-zDzXzCA8RWBMR9okgc2BvcyXi-JUOggrm7kWvPCTXmQF6m3tyzNP8lQAaeMDMUKW0riQ/file# [following]\n",
      "--2020-07-15 10:26:09--  https://uc36031389b61b3493f3f9bc803d.dl.dropboxusercontent.com/cd/0/inline/A7lJpPqc811NfH-q40zkD1CQ9uk6fKWLqesO-UHyd-zDzXzCA8RWBMR9okgc2BvcyXi-JUOggrm7kWvPCTXmQF6m3tyzNP8lQAaeMDMUKW0riQ/file\n",
      "Resolving uc36031389b61b3493f3f9bc803d.dl.dropboxusercontent.com (uc36031389b61b3493f3f9bc803d.dl.dropboxusercontent.com)... 162.125.82.15, 2620:100:6032:15::a27d:520f\n",
      "Connecting to uc36031389b61b3493f3f9bc803d.dl.dropboxusercontent.com (uc36031389b61b3493f3f9bc803d.dl.dropboxusercontent.com)|162.125.82.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 24450101 (23M) [text/plain]\n",
      "Saving to: ‘negative.csv?dl=0’\n",
      "\n",
      "negative.csv?dl=0   100%[===================>]  23.32M  16.0MB/s    in 1.5s    \n",
      "\n",
      "2020-07-15 10:26:11 (16.0 MB/s) - ‘negative.csv?dl=0’ saved [24450101/24450101]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "id": "1UhNgtnmpEzR",
    "outputId": "71c35300-85c0-43db-ddd9-f52f9f3d3ebb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'negative.csv?dl=0'  'positive.csv?dl=0'   sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_rzCPkpBnwzw"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "pos_texts = pd.read_csv('positive.csv?dl=0', encoding='utf8', sep=';', header=None)\n",
    "neg_texts = pd.read_csv('negative.csv?dl=0', encoding='utf8', sep=';', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "colab_type": "code",
    "id": "yWH7hHHYnwzz",
    "outputId": "55deed99-1501-4c37-dd81-47b2823e0b4d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8649</th>\n",
       "      <td>409111705256726528</td>\n",
       "      <td>1386374806</td>\n",
       "      <td>vemuvirycogyre</td>\n",
       "      <td>Офигенный день!\\nдень позитива)\\nбегал как иди...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>308</td>\n",
       "      <td>254</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21776</th>\n",
       "      <td>409427698600411137</td>\n",
       "      <td>1386450144</td>\n",
       "      <td>yaroslavkacenko</td>\n",
       "      <td>Час ночи. Лег раньше:-) А завтра пердячить, оо...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>670</td>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86921</th>\n",
       "      <td>410809322554535936</td>\n",
       "      <td>1386779549</td>\n",
       "      <td>saida_kzn</td>\n",
       "      <td>@cheerful_rabbit нормааально:з из Казани :с\\nЧ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3827</td>\n",
       "      <td>104</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36321</th>\n",
       "      <td>409829051822768128</td>\n",
       "      <td>1386545834</td>\n",
       "      <td>vitaliykylik</td>\n",
       "      <td>Ахахахахахахахах)) вот это называется 4 час но...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5165</td>\n",
       "      <td>273</td>\n",
       "      <td>182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22807</th>\n",
       "      <td>409484956420018176</td>\n",
       "      <td>1386463796</td>\n",
       "      <td>jilexowixag</td>\n",
       "      <td>не скрыть его приподнятого настроения! :DD htt...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>414</td>\n",
       "      <td>167</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0           1                2   ...   9    10  11\n",
       "8649   409111705256726528  1386374806   vemuvirycogyre  ...  254  251   0\n",
       "21776  409427698600411137  1386450144  yaroslavkacenko  ...   10   38   0\n",
       "86921  410809322554535936  1386779549        saida_kzn  ...  104  118   0\n",
       "36321  409829051822768128  1386545834     vitaliykylik  ...  273  182   1\n",
       "22807  409484956420018176  1386463796      jilexowixag  ...  167  183   0\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_texts.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vuk1KovBnwz4"
   },
   "source": [
    "Обратите внимание на специальные токены [CLS] и [SEP], которые мы добавляем в начало и конец предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vIJyJo8anwz5"
   },
   "outputs": [],
   "source": [
    "sentences = np.concatenate([pos_texts[3].values, neg_texts[3].values])\n",
    "\n",
    "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
    "labels = [[1] for _ in range(pos_texts.shape[0])] + [[0] for _ in range(neg_texts.shape[0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Av4GaA4Anwz9"
   },
   "outputs": [],
   "source": [
    "assert len(sentences) == len(labels) == pos_texts.shape[0] + neg_texts.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "id": "V2IxVE9Nnw0A",
    "outputId": "bb3b401c-ca53-47eb-8926-03d2213074a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] Дим, ты помогаешь мне, я тебе, все взаимно, все правильно) [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(sentences[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AOhiC7hUnw0E"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sentences, test_sentences, train_gt, test_gt = train_test_split(sentences, labels, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "id": "wX2yHxP-nw0G",
    "outputId": "b2cd6483-abf1-45ae-fff6-c398187eeb88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158783 68051\n"
     ]
    }
   ],
   "source": [
    "print(len(train_gt), len(test_gt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ex5O1eV-Pfct"
   },
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BTREubVNFiz4"
   },
   "source": [
    "Теперь импортируем токенизатор для BERT'а, который превратит наши тексты в набор токенов, соответствующих тем, что встречаются в словаре предобученной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "Z474sSC6oe7A",
    "outputId": "0ad8632f-bb50-479a-e4d5-35a71a4f8fbc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231508/231508 [00:00<00:00, 313598.85B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'в', '##ы', '##д', '##а', '##л', '##и', '50', 'а', '##н', '##к', '##е', '##т', 'д', '##л', '##я', 'о', '##п', '##р', '##о', '##с', '##а', 'н', '##а', '##с', '##е', '##л', '##е', '##н', '##ия', '!', ')', ')', 'з', '##а', '##ч', '##е', '##т', 'п', '##о', 'с', '##о', '##ц', '##и', '##о', '##л', '##о', '##г', '##ии', 'и', 'н', '##е', '##м', '##н', '##о', '##г', '##о', 'д', '##е', '##н', '##е', '##г', 'п', '##е', '##р', '##е', '##д', 'н', '##ов', '##ы', '##м', 'г', '##о', '##д', '##о', '##м', 'н', '##е', 'п', '##о', '##м', '##е', '##ш', '##а', '##ю', '##т', '!', '!', ')', ')', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "from pytorch_transformers import BertTokenizer, BertConfig\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in train_sentences]\n",
    "print (tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "87_kXUeT2-br"
   },
   "source": [
    "BERT'у нужно предоставить специальный формат входных данных.\n",
    "\n",
    "\n",
    "- **input ids**: последовательность чисел, отождествляющих каждый токен с его номером в словаре.\n",
    "- **labels**: вектор из нулей и единиц. В нашем случае нули обозначают негативную эмоциональную окраску, единицы - положительную.\n",
    "- **segment mask**: (необязательно) последовательность нулей и единиц, которая показывает, состоит ли входной текст из одного или двух предложений. Для случая одного предложения получится вектор из одних нулей. Для двух: <length_of_sent_1> нулей и <length_of_sent_2> единиц.\n",
    "- **attention mask**: (необязательно) последовательность нулей и единиц, где единицы обозначают токены предложения, нули - паддинг."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rd9JRevBnw0P"
   },
   "source": [
    "Паддинг нужен для того, чтобы BERT мог работать с предложениями разной длины. Выбираем максимально возможную длину предложения (в нашем случае пусть это будет 100). \n",
    "\n",
    "Теперь более длинные предложения будем обрезать до 100 токенов, а для более коротких использовать паддинг. Возьмем готовую функцию `pad_sequences` из библиотеки `keras`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cp9BPRd1tMIo"
   },
   "outputs": [],
   "source": [
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "input_ids = pad_sequences(\n",
    "    input_ids,\n",
    "    maxlen=100,\n",
    "    dtype=\"long\",\n",
    "    truncating=\"post\",\n",
    "    padding=\"post\"\n",
    ")\n",
    "attention_masks = [[float(i>0) for i in seq] for seq in input_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ba_bStOqnw0S"
   },
   "source": [
    "Делим данные на `train` и `val`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aFbE-UHvsb7-"
   },
   "outputs": [],
   "source": [
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(\n",
    "    input_ids, train_gt, \n",
    "    random_state=42,\n",
    "    test_size=0.1\n",
    ")\n",
    "\n",
    "train_masks, validation_masks, _, _ = train_test_split(\n",
    "    attention_masks,\n",
    "    input_ids,\n",
    "    random_state=42,\n",
    "    test_size=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PDfvfjIYnw0U"
   },
   "source": [
    "Преобразуем данные в `pytorch` тензоры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jw5K2A5Ko1RF"
   },
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(train_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_masks = torch.tensor(train_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h36Aaicbnw0X"
   },
   "outputs": [],
   "source": [
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "id": "NFe2nS2Dnw0Y",
    "outputId": "20023e58-4b3c-4dc6-97bd-50676444bd75"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [0],\n",
       "        ...,\n",
       "        [1],\n",
       "        [1],\n",
       "        [0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4wRIvr6ynw0a"
   },
   "source": [
    "Воспользуемся классом `DataLoader`. Это поможет нам использовать эффективнее память во время тренировки модели, так как нам не нужно будет загружать в память весь датасет. Данные по батчам будем разбивать произвольно с помощью RandomSampler. Также обратите внимание на размер батча: если во время тренировки возникнет `Memory Error`, размер батча необходимо уменьшить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GEgLpFVlo1Z-"
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    sampler=RandomSampler(train_data),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Psb9GPhSnw0c"
   },
   "outputs": [],
   "source": [
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_data,\n",
    "    sampler=SequentialSampler(validation_data),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pNl8khAhPYju"
   },
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZQtbXzAnw0g"
   },
   "source": [
    "Теперь когда данные подготовлены, надо написать пайплайн обучения модели.\n",
    "\n",
    "Для начала мы хотим изменить предобученный BERT так, чтобы он выдавал метки для классификации текстов, а затем файнтюнить его на наших данных. Мы возьмем готовую модификацию BERTа для классификации из pytorch-transformers. Она интуитивно понятно называется `BertForSequenceClassification`. Это обычный BERT с добавленным линейным слоем для классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LGadIqFznw0h"
   },
   "source": [
    "Загружаем [BertForSequenceClassification](https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/pytorch_pretrained_bert/modeling.py#L1129):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vq3DCIz_nw0k"
   },
   "outputs": [],
   "source": [
    "from pytorch_transformers import AdamW, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kajIrYM1nw0r"
   },
   "source": [
    "Аналогичные модели есть и для других задач. Все они построены на основе одной и той же архитектуры и различаются только верхними слоями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J3f4S3STnw0r"
   },
   "outputs": [],
   "source": [
    "from pytorch_transformers import BertForQuestionAnswering, BertForTokenClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9eVbh0Iynw0t"
   },
   "source": [
    "Теперь подробнее рассмотрим процесс файн-тюнинга. Как мы помним, первый токен в каждом предложении - это `[CLS]`. В отличие от скрытого состояния, относящего к обычному слову (не метке `[CLS]`), скрытое состояние относящееся к этой метке должно содержать в себе аггрегированное представление всего предложения, которое дальше будет использоваться для классификации. Таким образом, когда мы скормили предложение в процессе обучения сети, выходом будет вектор со скрытым состоянием, относящийся к метке `[CLS]`. Дополнительный полносвязный слой, который мы добавили, имеет размер `[hidden_state, количество_классов]`, в нашем случае количество классов равно двум. То есть нав выходе мы получим два числа, представляющих классы \"положительная эмоциональная окраска\" и \"отрицательная эмоциональная окраска\".\n",
    "\n",
    "Процесс дообучения достаточно дешев. По факту мы тренируем наш верхний слой и немного меняем веса во всех остальных слоях в процессе, чтобы подстроиться под нашу задачу.\n",
    "\n",
    "Иногда некоторые слои специально \"замораживают\" или применяют разные стратегии работы с learning rate, в общем, делают все, чтобы сохранить \"хорошие\" веса в нижних слоях и ускорить дообучение. В целом, замораживание слоев BERTа обычно не сильно сказывается на итоговом качестве, однако надо помнить о тех случаях, когда данные, использованные для предобучения и дообучения очень разные (разные домены или стиль: академическая и разговорная лексика). В таких случаях лучше тренировать все слои сети, не замораживая ничего."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WnQW9E-bBCRt"
   },
   "source": [
    "Загружаем BERT. `bert-base-uncased` - это версия \"base\" (в оригинальной статье рассказывается про две модели: \"base\" vs \"large\"), где есть только буквы в нижнем регистре (\"uncased\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "gFsCTp_mporB",
    "outputId": "df5167be-0194-45fe-e291-2681d10708fe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 433/433 [00:00<00:00, 102473.26B/s]\n",
      "100%|██████████| 440473133/440473133 [00:35<00:00, 12300516.96B/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T04gkz4znw0v"
   },
   "source": [
    "Теперь обсудим гиперпараметры для обучения нашей модели. Авторы статьи советуют выбирать `learning rate` `5e-5`, `3e-5`, `2e-5`, а количество эпох не делать слишком большим, 2-4 вполне достаточно. Мы пойдем еще дальше и попробуем дообучить нашу модель всего за одну эпоху."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QxSMw0FrptiL"
   },
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "colab_type": "code",
    "id": "6J-FYdx6nFE_",
    "outputId": "7533835a-940b-48c8-db58-72b3dbfc623f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss на обучающей выборке: 0.03658\n",
      "Процент правильных предсказаний на валидационной выборке: 97.86%\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# Будем сохранять loss во время обучения\n",
    "# и рисовать график в режиме реального времени\n",
    "train_loss_set = []\n",
    "train_loss = 0\n",
    "\n",
    "\n",
    "# Обучение\n",
    "# Переводим модель в training mode\n",
    "model.train()\n",
    "\n",
    "\n",
    "for step, batch in enumerate(train_dataloader):\n",
    "    # добавляем батч для вычисления на GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Распаковываем данные из dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # если не сделать .zero_grad(), градиенты будут накапливаться\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "\n",
    "    train_loss_set.append(loss[0].item())  \n",
    "    \n",
    "    # Backward pass\n",
    "    loss[0].backward()\n",
    "    \n",
    "    # Обновляем параметры и делаем шаг используя посчитанные градиенты\n",
    "    optimizer.step()\n",
    "\n",
    "    # Обновляем loss\n",
    "    train_loss += loss[0].item()\n",
    "    \n",
    "    # Рисуем график\n",
    "    clear_output(True)\n",
    "    plt.plot(train_loss_set)\n",
    "    plt.title(\"Training loss\")\n",
    "    plt.xlabel(\"Batch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "    \n",
    "print(\"Loss на обучающей выборке: {0:.5f}\".format(train_loss / len(train_dataloader)))\n",
    "\n",
    "\n",
    "# Валидация\n",
    "# Переводим модель в evaluation mode\n",
    "model.eval()\n",
    "\n",
    "valid_preds, valid_labels = [], []\n",
    "\n",
    "for batch in validation_dataloader:   \n",
    "    # добавляем батч для вычисления на GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # Распаковываем данные из dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n",
    "    # Это ускорит процесс предсказания меток для валидационных данных.\n",
    "    with torch.no_grad():\n",
    "        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "\n",
    "    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n",
    "    logits = logits[0].detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    batch_preds = np.argmax(logits, axis=1)\n",
    "    batch_labels = np.concatenate(label_ids)     \n",
    "    valid_preds.extend(batch_preds)\n",
    "    valid_labels.extend(batch_labels)\n",
    "\n",
    "print(\"Процент правильных предсказаний на валидационной выборке: {0:.2f}%\".format(\n",
    "    accuracy_score(valid_labels, valid_preds) * 100\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "up6VFTX0nw0_",
    "outputId": "8e171c1a-6593-41ad-aea8-a59da9862f44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процент правильных предсказаний на валидационной выборке: 97.86%\n"
     ]
    }
   ],
   "source": [
    "print(\"Процент правильных предсказаний на валидационной выборке: {0:.2f}%\".format(\n",
    "    accuracy_score(valid_labels, valid_preds) * 100\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mkyubuJSOzg3"
   },
   "source": [
    "# Оценка качества на отложенной выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mAwAnOHknw1T"
   },
   "source": [
    "Качество на валидационной выборке оказалось очень хорошим. Не переобучилась ли наша модель?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A--4t6QEnw1U"
   },
   "source": [
    "Делаем точно такую же предобработку для тестовых данных, как и в начале ноутбука делали для обучающих данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mAN0LZBOOPVh"
   },
   "outputs": [],
   "source": [
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in test_sentences]\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "\n",
    "input_ids = pad_sequences(\n",
    "    input_ids,\n",
    "    maxlen=100,\n",
    "    dtype=\"long\",\n",
    "    truncating=\"post\",\n",
    "    padding=\"post\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fTF0_Paenw1V"
   },
   "source": [
    "Создаем attention маски и приводим данные в необходимый формат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I9tvbH-Dnw1W"
   },
   "outputs": [],
   "source": [
    "attention_masks = [[float(i>0) for i in seq] for seq in input_ids]\n",
    "\n",
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "prediction_labels = torch.tensor(test_gt)\n",
    "\n",
    "prediction_data = TensorDataset(\n",
    "    prediction_inputs,\n",
    "    prediction_masks,\n",
    "    prediction_labels\n",
    ")\n",
    "\n",
    "prediction_dataloader = DataLoader(\n",
    "    prediction_data, \n",
    "    sampler=SequentialSampler(prediction_data),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hba10sXR7Xi6"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_preds, test_labels = [], []\n",
    "\n",
    "for batch in prediction_dataloader:\n",
    "    # добавляем батч для вычисления на GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # Распаковываем данные из dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n",
    "    # Это ускорит процесс предсказания меток для тестовых данных.\n",
    "    with torch.no_grad():\n",
    "        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "\n",
    "    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n",
    "    logits = logits[0].detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # Сохраняем предсказанные классы и ground truth\n",
    "    batch_preds = np.argmax(logits, axis=1)\n",
    "    batch_labels = np.concatenate(label_ids)  \n",
    "    test_preds.extend(batch_preds)\n",
    "    test_labels.extend(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "id": "RVrx_hZIfCvl",
    "outputId": "0e707597-6d59-43a2-8aac-4dbd2607bf01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9790304330575598"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "id": "fHzpDK0snw1m",
    "outputId": "8b839a97-bfa2-4284-95e8-ed8312516bd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процент правильных предсказаний на отложенной выборке составил: 97.90%\n"
     ]
    }
   ],
   "source": [
    "acc_score = accuracy_score(test_labels, test_preds)\n",
    "print('Процент правильных предсказаний на отложенной выборке составил: {0:.2f}%'.format(\n",
    "    acc_score * 100\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uc5roFLrfGsX"
   },
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "id": "jpX55gjlnw1n",
    "outputId": "1c21c165-5f21-4f9a-b75b-6aab04eb64f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Неправильных предсказаний: 1427/68051\n"
     ]
    }
   ],
   "source": [
    "print('Неправильных предсказаний: {0}/{1}'.format(\n",
    "    sum(np.array(test_labels) != np.array(test_preds)),\n",
    "    len(test_labels)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BRZv3IAcnw2G"
   },
   "source": [
    "### Оценка качества работы без fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KBCR5Wm3nw2G"
   },
   "outputs": [],
   "source": [
    "model_wo_finetuning = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "model_wo_finetuning.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lje6hqLgnw2H"
   },
   "outputs": [],
   "source": [
    "model_wo_finetuning.eval()\n",
    "preds_wo_finetuning, labels_wo_finetuning = [], []\n",
    "\n",
    "for batch in prediction_dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    with torch.no_grad():\n",
    "        logits = model_wo_finetuning(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "\n",
    "    logits = logits[0].detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    batch_preds = np.argmax(logits, axis=1)\n",
    "    batch_labels = np.concatenate(label_ids)  \n",
    "    preds_wo_finetuning.extend(batch_preds)\n",
    "    labels_wo_finetuning.extend(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "id": "reQ-uyPLnw2I",
    "outputId": "702c6860-15a9-4f68-ee62-4baa69933721"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процент правильных предсказаний на отложенной выборке составил: 57.10%\n"
     ]
    }
   ],
   "source": [
    "acc_score_wo_finetuning = accuracy_score(labels_wo_finetuning, preds_wo_finetuning)\n",
    "print('Процент правильных предсказаний на отложенной выборке составил: {0:.2f}%'.format(\n",
    "    acc_score_wo_finetuning*100\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CRYA-dB4nw2J"
   },
   "source": [
    "Сравним точность и полноту предсказаний:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "id": "EYXYQjKfnw2K",
    "outputId": "01e886ed-3470-4d98-d93b-b6bee3974be7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 эпоха: точность (precision) 96.74%, полнота (recall) 99.19%\n",
      "Без дообучения: точность (precision) 59.86%, полнота (recall) 45.78%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score\n",
    "\n",
    "print('1 эпоха: точность (precision) {0:.2f}%, полнота (recall) {1:.2f}%'.format(\n",
    "    precision_score(test_labels, test_preds) * 100,\n",
    "    recall_score(test_labels, test_preds) * 100\n",
    "))\n",
    " \n",
    "print('Без дообучения: точность (precision) {0:.2f}%, полнота (recall) {1:.2f}%'.format(\n",
    "    precision_score(labels_wo_finetuning, preds_wo_finetuning) * 100,\n",
    "    recall_score(labels_wo_finetuning, preds_wo_finetuning) * 100,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lv10x-Hnw2L"
   },
   "source": [
    "Итак, мы показали, что предобученный BERT может быстро (всего за одну эпоху) давать хорошее качество при решении задачи анализа эмоциональной окраски текстов. Обратите внимание, что мы не тюнили параметры и использовали сравнительно небольшой размеченный корпус, чтобы получить accuracy больше 98\\%. Тем не менее, если не делать дообучения под конкретную задачу вовсе, получить хорошее качество не удается.\n",
    "\n",
    "Кроме того, мы познакомились с библиотекой `pytorch-transformers`, которая позволяет использовать готовые обертки над моделями, специально созданными для решения той или иной задачи. Использовать BERT при решении повседневных NLP задач совсем нетрудно: не нужно даже вручную скачивать веса модели, библиотека все сделает за вас. Отбросив необходимость чуть-чуть предобработать тексты, сложность применения предобученного BERT'а оказывается не сильно больше, чем импортировать и применить лог.регрессию из `sklearn`."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT-15761-3cb2c8.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
